# Whisper Speech-to-Text API ğŸ¤â¡ï¸ğŸ“

This is a simple API that converts **speech (audio)** into **text** using OpenAIâ€™s pre-trained **Whisper model** (via `faster-whisper`).  
It is built with **FastAPI** and runs locally or on a server.

## ğŸš€ Features
- Accepts audio files (`.mp3`, `.wav`, `.m4a`, etc.).
- Auto language detection (works for English, Urdu, Hindi, Arabic, etc.).
- Returns transcription in JSON format.
- Easy to run with Python.


## ğŸ› ï¸ Installation & Setup

### 1. Clone this repository
```bash
git clone https://github.com/YOUR_USERNAME/whisper-api.git
cd whisper-api

### 2. Install dependencies
Make sure you have Python 3.9+ installed, then run:


pip install -r requirements.txt
Also install ffmpeg:

Windows: choco install ffmpeg

Linux (Debian/Ubuntu): sudo apt-get install ffmpeg

### 3. Run the API

python -m uvicorn main:app --reload
You should see:

Uvicorn running on http://127.0.0.1:8000
ğŸ“Œ Usage
Open your browser at ğŸ‘‰ http://127.0.0.1:8000/docs
(Swagger UI will appear).

Click on POST /transcribe â†’ Try it out.

Upload an audio file and press Execute.

Youâ€™ll get a JSON response like:


{
  "language": "en",
  "text": "Hello, how are you?"
}

ğŸ“¦ API Endpoint
POST /transcribe
Input: audio file (.mp3, .wav, .m4a)

Output: JSON

{
  "language": "ur",
  "text": "Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚº"
}
ğŸ”§ Configurations
In main.py you can change:


model = WhisperModel("small", device="cpu", compute_type="int8")
Models: tiny, base, small, medium, large-v3

Device: "cpu" or "cuda" (if GPU available)

Compute type: int8, float16, float32 (affects speed/accuracy)

ğŸ‘¨â€ğŸ’» Author
Developed by Ahmed Ali during internship.
Uses OpenAI Whisper + FastAPI.

